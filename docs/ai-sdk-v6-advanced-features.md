# AI SDK v6 é«˜çº§åŠŸèƒ½é€ŸæŸ¥

> ä»ç±»å‹æ–‡ä»¶æŒ–æ˜å‡ºçš„å®ç”¨åŠŸèƒ½
> åŸºäº AI SDK 6.0.67

## ç›®å½•

1. [æ¶ˆæ¯å¤„ç†å·¥å…·](#æ¶ˆæ¯å¤„ç†å·¥å…·)
2. [è¾“å‡ºæ ¼å¼æ§åˆ¶ï¼ˆOutputï¼‰](#è¾“å‡ºæ ¼å¼æ§åˆ¶output)
3. [ä¸­é—´ä»¶ç³»ç»Ÿï¼ˆMiddlewareï¼‰](#ä¸­é—´ä»¶ç³»ç»Ÿmiddleware)
4. [åœæ­¢æ¡ä»¶ï¼ˆStop Conditionsï¼‰](#åœæ­¢æ¡ä»¶stop-conditions)
5. [æµå¼ä¼˜åŒ–ï¼ˆStream Optimizationï¼‰](#æµå¼ä¼˜åŒ–stream-optimization)
6. [ç±»å‹å®ˆå«ï¼ˆType Guardsï¼‰](#ç±»å‹å®ˆå«type-guards)
7. [åµŒå…¥å’Œå‘é‡ï¼ˆEmbeddingsï¼‰](#åµŒå…¥å’Œå‘é‡embeddings)
8. [å¤šæ¨¡æ€åŠŸèƒ½](#å¤šæ¨¡æ€åŠŸèƒ½)

---

## æ¶ˆæ¯å¤„ç†å·¥å…·

### 1. pruneMessages - æ¶ˆæ¯ä¿®å‰ª

**ç”¨é€”ï¼š** åœ¨é•¿å¯¹è¯ä¸­ï¼Œå‡å°‘ token ä½¿ç”¨ï¼Œç§»é™¤ä¸å¿…è¦çš„å†å²æ¶ˆæ¯ã€‚

```typescript
import { pruneMessages } from 'ai';

const prunedMessages = pruneMessages({
  messages: conversationHistory,

  // æ¨ç†å†…å®¹ä¿ç•™ç­–ç•¥
  reasoning: 'all' |                      // ä¿ç•™æ‰€æœ‰æ¨ç†
            'before-last-message' |       // åªä¿ç•™æœ€åä¸€æ¡æ¶ˆæ¯å‰çš„æ¨ç†
            'none',                       // ç§»é™¤æ‰€æœ‰æ¨ç†

  // å·¥å…·è°ƒç”¨ä¿ç•™ç­–ç•¥
  toolCalls: 'all' |                      // ä¿ç•™æ‰€æœ‰å·¥å…·è°ƒç”¨
             'before-last-message' |       // åªä¿ç•™æœ€åä¸€æ¡æ¶ˆæ¯å‰çš„
             'before-last-3-messages' |    // æœ€å3æ¡æ¶ˆæ¯å‰çš„
             'none' |                      // ç§»é™¤æ‰€æœ‰
             [                             // è‡ªå®šä¹‰ç­–ç•¥
               {
                 type: 'before-last-message',
                 tools: ['search', 'calculator']  // åªä¿ç•™ç‰¹å®šå·¥å…·
               }
             ],

  // ç©ºæ¶ˆæ¯å¤„ç†
  emptyMessages: 'keep' | 'remove',
});
```

**å®æˆ˜ç¤ºä¾‹ï¼š**

```typescript
// åœºæ™¯ï¼šé•¿å¯¹è¯ä¼˜åŒ–
const { messages, sendMessage } = useChat();

// å‘é€å‰ä¿®å‰ªå†å²æ¶ˆæ¯
const handleSend = async (text: string) => {
  const prunedMessages = pruneMessages({
    messages: convertToModelMessages(messages),
    reasoning: 'none',  // æ¨ç†è¿‡ç¨‹ç”¨æˆ·çœ‹ä¸åˆ°ï¼Œå¯ä»¥åˆ é™¤
    toolCalls: 'before-last-5-messages',  // åªä¿ç•™æœ€è¿‘5æ¡çš„å·¥å…·è°ƒç”¨
    emptyMessages: 'remove',
  });

  await sendMessage(text, {
    body: { messages: prunedMessages }
  });
};
```

### 2. convertToModelMessages - æ¶ˆæ¯æ ¼å¼è½¬æ¢

**ç”¨é€”ï¼š** å°† `UIMessage` è½¬æ¢ä¸º `ModelMessage`ï¼ˆå‘é€ç»™ AI çš„æ ¼å¼ï¼‰ã€‚

```typescript
import { convertToModelMessages } from 'ai';

const modelMessages = convertToModelMessages(
  uiMessages,
  {
    tools: myTools,  // å·¥å…·å®šä¹‰
    ignoreIncompleteToolCalls: false,  // æ˜¯å¦å¿½ç•¥æœªå®Œæˆçš„å·¥å…·è°ƒç”¨

    // è‡ªå®šä¹‰æ•°æ®éƒ¨åˆ†è½¬æ¢
    convertDataPart: (part) => {
      if (part.type === 'data-userProfile') {
        return {
          type: 'text',
          text: `User profile: ${JSON.stringify(part.data)}`
        };
      }
      return undefined;  // å¿½ç•¥æ­¤éƒ¨åˆ†
    }
  }
);
```

### 3. convertFileListToFileUIParts - æ–‡ä»¶ä¸Šä¼ 

**ç”¨é€”ï¼š** å°†æµè§ˆå™¨çš„ `FileList` è½¬æ¢ä¸º `FileUIPart`ï¼ˆç”¨äºå¤šæ¨¡æ€æ¶ˆæ¯ï¼‰ã€‚

```typescript
import { convertFileListToFileUIParts } from 'ai';

// React æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
const FileUpload = () => {
  const { sendMessage } = useChat();

  const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const files = e.target.files;

    // è½¬æ¢æ–‡ä»¶åˆ—è¡¨
    const fileParts = await convertFileListToFileUIParts(files);

    // å‘é€å¸¦æ–‡ä»¶çš„æ¶ˆæ¯
    sendMessage({
      text: 'è¯·åˆ†æè¿™äº›å›¾ç‰‡',
      parts: [
        { type: 'text', text: 'è¯·åˆ†æè¿™äº›å›¾ç‰‡' },
        ...fileParts,  // æ·»åŠ æ–‡ä»¶
      ]
    });
  };

  return <input type="file" multiple onChange={handleFileUpload} />;
};
```

---

## è¾“å‡ºæ ¼å¼æ§åˆ¶ï¼ˆOutputï¼‰

### output.text() - çº¯æ–‡æœ¬è¾“å‡º

```typescript
import { generateText, output } from 'ai';

const result = await generateText({
  model: chatModel,
  prompt: 'å†™ä¸€ç¯‡æ–‡ç« ',
  output: output.text(),  // æ˜ç¡®æŒ‡å®šè¾“å‡ºæ–‡æœ¬
});

console.log(result.text);  // string
```

### output.object() - ç»“æ„åŒ–å¯¹è±¡

**ç”¨é€”ï¼š** æ›¿ä»£å·²åºŸå¼ƒçš„ `generateObject`ï¼Œä½¿ç”¨ `generateText` + `output.object()`ã€‚

```typescript
import { generateText, output } from 'ai';
import { z } from 'zod';

// å®šä¹‰ Schema
const recipeSchema = z.object({
  name: z.string(),
  ingredients: z.array(z.string()),
  steps: z.array(z.string()),
  cookingTime: z.number(),
});

// ç”Ÿæˆç»“æ„åŒ–æ•°æ®
const result = await generateText({
  model: chatModel,
  prompt: 'ç»™æˆ‘ä¸€ä¸ªç•ªèŒ„ç‚’è›‹çš„é£Ÿè°±',
  output: output.object({
    schema: recipeSchema,
    name: 'recipe',  // å¯é€‰ï¼šå·¥å…·åç§°æç¤º
    description: 'ä¸­å¼å®¶å¸¸èœé£Ÿè°±',  // å¯é€‰ï¼šæè¿°
  }),
});

// ç±»å‹å®‰å…¨çš„ç»“æœ
const recipe = result.object;  // { name: string, ingredients: string[], ... }
console.log(recipe.name);
console.log(recipe.ingredients);
```

### output.array() - æ•°ç»„è¾“å‡º

```typescript
const result = await generateText({
  model: chatModel,
  prompt: 'åˆ—å‡º10ä¸ªç¼–ç¨‹è¯­è¨€',
  output: output.array({
    element: z.string(),
    name: 'programmingLanguages',
    description: 'ç¼–ç¨‹è¯­è¨€åˆ—è¡¨',
  }),
});

const languages = result.object;  // string[]
```

### output.choice() - æšä¸¾é€‰æ‹©

```typescript
const result = await generateText({
  model: chatModel,
  prompt: 'è¿™æ®µè¯„è®ºçš„æƒ…æ„Ÿæ˜¯ï¼Ÿï¼š"è¿™ä¸ªäº§å“çœŸæ£’ï¼"',
  output: output.choice({
    options: ['positive', 'negative', 'neutral'],
    name: 'sentiment',
    description: 'æƒ…æ„Ÿåˆ†æç»“æœ',
  }),
});

const sentiment = result.object;  // 'positive' | 'negative' | 'neutral'
```

### output.json() - éç»“æ„åŒ– JSON

```typescript
const result = await generateText({
  model: chatModel,
  prompt: 'ç”Ÿæˆä¸€ä¸ªç”¨æˆ·é…ç½® JSON',
  output: output.json({
    name: 'userConfig',
    description: 'ç”¨æˆ·é…ç½®å¯¹è±¡',
  }),
});

const config = result.object;  // JSONValue (any JSON)
```

---

## ä¸­é—´ä»¶ç³»ç»Ÿï¼ˆMiddlewareï¼‰

### extractReasoningMiddleware - æå–æ¨ç†è¿‡ç¨‹

**ç”¨é€”ï¼š** æå– AI çš„"æ€è€ƒè¿‡ç¨‹"ï¼ˆå¦‚ o1 æ¨¡å‹çš„æ¨ç†ï¼‰ï¼Œå•ç‹¬æ˜¾ç¤ºã€‚

```typescript
import { wrapLanguageModel, extractReasoningMiddleware } from 'ai';

const modelWithReasoning = wrapLanguageModel({
  model: chatModel,
  middleware: extractReasoningMiddleware({
    tagName: 'thinking',  // XML æ ‡ç­¾å
    separator: '\n\n---\n\n',  // åˆ†éš”ç¬¦
    startWithReasoning: true,  // æ¨ç†åœ¨å‰ï¼Œå›å¤åœ¨å
  }),
});

const result = await generateText({
  model: modelWithReasoning,
  prompt: 'è®¡ç®— 123 * 456',
});

console.log(result.reasoning);  // "Let me break this down..."
console.log(result.text);       // "56088"
```

**UI ç¤ºä¾‹ï¼š**

```tsx
const ChatMessage = ({ message }) => {
  const reasoning = message.parts.find(p => p.type === 'reasoning');
  const text = message.parts.find(p => p.type === 'text');

  return (
    <div>
      {reasoning && (
        <details className="mb-4">
          <summary className="cursor-pointer text-gray-500">
            ğŸ’­ æŸ¥çœ‹ AI æ€è€ƒè¿‡ç¨‹
          </summary>
          <pre className="bg-gray-100 p-4 rounded mt-2">
            {reasoning.text}
          </pre>
        </details>
      )}
      <div>{text?.text}</div>
    </div>
  );
};
```

### extractJsonMiddleware - æå– JSON

**ç”¨é€”ï¼š** ä» Markdown ä»£ç å—ä¸­æå– JSONï¼ˆå¤„ç†ä¸è§„èŒƒçš„æ¨¡å‹è¾“å‡ºï¼‰ã€‚

```typescript
import { wrapLanguageModel, extractJsonMiddleware } from 'ai';

const modelWithJsonExtraction = wrapLanguageModel({
  model: chatModel,
  middleware: extractJsonMiddleware({
    transform: (text) => {
      // è‡ªå®šä¹‰è½¬æ¢é€»è¾‘
      // é»˜è®¤ï¼šç§»é™¤ ```json ... ``` åŒ…è£¹
      return text.replace(/```json\n([\s\S]*?)\n```/g, '$1');
    }
  }),
});

// å³ä½¿æ¨¡å‹è¿”å› ```json {"name": "test"} ```
// ä¹Ÿèƒ½æ­£ç¡®è§£æä¸º JSON å¯¹è±¡
const result = await generateText({
  model: modelWithJsonExtraction,
  prompt: 'ç”Ÿæˆä¸€ä¸ª JSON',
  output: output.json(),
});
```

### addToolInputExamplesMiddleware - å·¥å…·ç¤ºä¾‹

**ç”¨é€”ï¼š** å°†å·¥å…·çš„ `inputExamples` æ·»åŠ åˆ°æè¿°ä¸­ï¼ˆç”¨äºä¸æ”¯æŒç¤ºä¾‹çš„æ¨¡å‹ï¼‰ã€‚

```typescript
import { tool, wrapLanguageModel, addToolInputExamplesMiddleware } from 'ai';

const searchTool = tool({
  description: 'æœç´¢ç½‘ç»œå†…å®¹',
  inputSchema: z.object({
    query: z.string(),
    maxResults: z.number().optional(),
  }),
  // æ·»åŠ ç¤ºä¾‹
  inputExamples: [
    { query: 'AI SDK v6 documentation', maxResults: 5 },
    { query: 'Next.js 15 features' },
  ],
  execute: async ({ query }) => { /* ... */ },
});

const modelWithExamples = wrapLanguageModel({
  model: chatModel,
  middleware: addToolInputExamplesMiddleware({
    prefix: 'ç¤ºä¾‹è¾“å…¥ï¼š',  // è‡ªå®šä¹‰å‰ç¼€
    format: (example, index) => {
      // è‡ªå®šä¹‰æ ¼å¼åŒ–
      return `${index + 1}. ${JSON.stringify(example.input)}`;
    },
    remove: true,  // æ·»åŠ åç§»é™¤ inputExamples å±æ€§
  }),
});

// å·¥å…·æè¿°ä¼šå˜æˆï¼š
// "æœç´¢ç½‘ç»œå†…å®¹\n\nç¤ºä¾‹è¾“å…¥ï¼š\n1. {\"query\":\"AI SDK v6 documentation\",\"maxResults\":5}\n2. {\"query\":\"Next.js 15 features\"}"
```

### simulateStreamingMiddleware - æ¨¡æ‹Ÿæµå¼

**ç”¨é€”ï¼š** å°† `generateText` çš„ç»“æœæ¨¡æ‹Ÿæˆæµå¼è¾“å‡ºï¼ˆç”¨äºæµ‹è¯•æˆ–ç»Ÿä¸€æ¥å£ï¼‰ã€‚

```typescript
import { wrapLanguageModel, simulateStreamingMiddleware } from 'ai';

const modelWithSimulatedStreaming = wrapLanguageModel({
  model: chatModel,
  middleware: simulateStreamingMiddleware(),
});

// å³ä½¿ä½¿ç”¨ generateTextï¼Œä¹Ÿä¼šæ¨¡æ‹Ÿæµå¼è¾“å‡º
const result = await generateText({
  model: modelWithSimulatedStreaming,
  prompt: 'Hello',
});
```

---

## åœæ­¢æ¡ä»¶ï¼ˆStop Conditionsï¼‰

### stepCountIs - é™åˆ¶æ­¥éª¤æ•°

**ç”¨é€”ï¼š** é™åˆ¶ Agent çš„æœ€å¤§æ­¥éª¤æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰ã€‚

```typescript
import { stepCountIs } from 'ai';

const result = await interviewAgent.run({
  prompt: 'å¸®æˆ‘è§„åˆ’è¯¾ç¨‹',
  stopCondition: stepCountIs(5),  // æœ€å¤šæ‰§è¡Œ 5 æ­¥
});
```

### hasToolCall - æ£€æµ‹å·¥å…·è°ƒç”¨

**ç”¨é€”ï¼š** å½“è°ƒç”¨ç‰¹å®šå·¥å…·æ—¶åœæ­¢ Agentã€‚

```typescript
import { hasToolCall } from 'ai';

const result = await interviewAgent.run({
  prompt: 'å¸®æˆ‘è§„åˆ’è¯¾ç¨‹',
  stopCondition: hasToolCall('generateOutline'),  // è°ƒç”¨ generateOutline ååœæ­¢
});
```

**ç»„åˆæ¡ä»¶ï¼š**

```typescript
// è‡ªå®šä¹‰åœæ­¢æ¡ä»¶
const customStopCondition = (stepResult) => {
  // è¾¾åˆ° 10 æ­¥æˆ–è°ƒç”¨äº† generateOutline
  return stepResult.stepCount >= 10 ||
         stepResult.toolCalls.some(tc => tc.toolName === 'generateOutline');
};
```

---

## æµå¼ä¼˜åŒ–ï¼ˆStream Optimizationï¼‰

### smoothStream - å¹³æ»‘æµå¼è¾“å‡º

**ç”¨é€”ï¼š** æ§åˆ¶æµå¼è¾“å‡ºçš„èŠ‚å¥ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼ˆé€å­—ã€é€è¯ã€é€è¡Œï¼‰ã€‚

```typescript
import { streamText, smoothStream } from 'ai';

const result = await streamText({
  model: chatModel,
  prompt: 'å†™ä¸€é¦–è¯—',
  experimental_transform: smoothStream({
    delayInMs: 10,  // æ¯ä¸ª chunk ä¹‹é—´å»¶è¿Ÿ 10ms

    // åˆ†å—ç­–ç•¥
    chunking: 'word' |          // é€è¯è¾“å‡ºï¼ˆé»˜è®¤ï¼Œè‹±æ–‡å‹å¥½ï¼‰
              'line' |          // é€è¡Œè¾“å‡º
              /\s+/ |           // è‡ªå®šä¹‰æ­£åˆ™ï¼ˆæŒ‰ç©ºæ ¼ï¼‰
              new Intl.Segmenter('zh-CN', { granularity: 'word' }) |  // ä¸­æ–‡åˆ†è¯
              (buffer) => {     // è‡ªå®šä¹‰æ£€æµ‹å‡½æ•°
                // è¿”å›ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„ chunk
                return buffer.match(/[ã€‚ï¼ï¼Ÿ]/)?.[0];
              },
  }),
});
```

**å®æˆ˜ç¤ºä¾‹ï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰ï¼š**

```typescript
// ä½¿ç”¨ Intl.Segmenter å®ç°ä¸­æ–‡é€å­—è¾“å‡º
const result = await streamText({
  model: chatModel,
  prompt: 'ä»‹ç»ä¸€ä¸‹åŒ—äº¬',
  experimental_transform: smoothStream({
    delayInMs: 50,  // 50ms ä¸€ä¸ªå­—
    chunking: new Intl.Segmenter('zh-CN', { granularity: 'grapheme' }),
  }),
});

// å‰ç«¯æ•ˆæœï¼šåŒ— â†’ äº¬ â†’ æ˜¯ â†’ ä¸­ â†’ å›½ â†’ çš„ â†’ é¦– â†’ éƒ½ ...
```

---

## ç±»å‹å®ˆå«ï¼ˆType Guardsï¼‰

### æ£€æµ‹æ¶ˆæ¯éƒ¨åˆ†ç±»å‹

```typescript
import {
  isTextUIPart,
  isToolUIPart,
  isReasoningUIPart,
  isFileUIPart,
  getToolName,
} from 'ai';

message.parts.forEach((part) => {
  if (isTextUIPart(part)) {
    console.log('æ–‡æœ¬:', part.text);
  }

  if (isReasoningUIPart(part)) {
    console.log('æ¨ç†:', part.text);
  }

  if (isToolUIPart(part)) {
    const toolName = getToolName(part);  // 'presentOptions'
    console.log('å·¥å…·è°ƒç”¨:', toolName, part.input);
  }

  if (isFileUIPart(part)) {
    console.log('æ–‡ä»¶:', part.filename, part.url);
  }
});
```

**ç±»å‹å®‰å…¨çš„å·¥å…·å¤„ç†ï¼š**

```typescript
import { isStaticToolUIPart, getStaticToolName } from 'ai';

// åªå¤„ç†å·²çŸ¥çš„é™æ€å·¥å…·
if (isStaticToolUIPart(part)) {
  const toolName = getStaticToolName(part);  // keyof typeof toolsï¼ˆç±»å‹å®‰å…¨ï¼‰

  if (toolName === 'presentOptions') {
    // TypeScript çŸ¥é“ part.input çš„ç±»å‹
    const { question, options } = part.input;
  }
}
```

---

## åµŒå…¥å’Œå‘é‡ï¼ˆEmbeddingsï¼‰

### embed - å•ä¸ªåµŒå…¥

```typescript
import { embed } from 'ai';
import { openai } from '@ai-sdk/openai';

const { embedding } = await embed({
  model: openai.embedding('text-embedding-3-small'),
  value: 'äººå·¥æ™ºèƒ½çš„æœªæ¥',
});

console.log(embedding);  // number[] (å‘é‡)
```

### embedMany - æ‰¹é‡åµŒå…¥

```typescript
import { embedMany } from 'ai';

const { embeddings } = await embedMany({
  model: openai.embedding('text-embedding-3-small'),
  values: [
    'æ–‡æ¡£1å†…å®¹',
    'æ–‡æ¡£2å†…å®¹',
    'æ–‡æ¡£3å†…å®¹',
  ],
  maxParallelCalls: 5,  // æœ€å¤š5ä¸ªå¹¶è¡Œè¯·æ±‚
});

embeddings.forEach((emb, i) => {
  console.log(`æ–‡æ¡£${i + 1}å‘é‡:`, emb);
});
```

### cosineSimilarity - ä½™å¼¦ç›¸ä¼¼åº¦

```typescript
import { embed, cosineSimilarity } from 'ai';

const { embedding: emb1 } = await embed({
  model: embeddingModel,
  value: 'æŸ¥è¯¢æ–‡æœ¬',
});

const { embedding: emb2 } = await embed({
  model: embeddingModel,
  value: 'å€™é€‰æ–‡æ¡£',
});

const similarity = cosineSimilarity(emb1, emb2);  // 0.0 - 1.0
console.log('ç›¸ä¼¼åº¦:', similarity);
```

### rerank - æ–‡æ¡£é‡æ’åº

**ç”¨é€”ï¼š** ä½¿ç”¨ä¸“é—¨çš„ reranking æ¨¡å‹å¯¹æœç´¢ç»“æœé‡æ–°æ’åºã€‚

```typescript
import { rerank } from 'ai';
import { cohere } from '@ai-sdk/cohere';

const documents = [
  { id: 1, text: 'æ–‡æ¡£1å†…å®¹...' },
  { id: 2, text: 'æ–‡æ¡£2å†…å®¹...' },
  { id: 3, text: 'æ–‡æ¡£3å†…å®¹...' },
];

const { rankings } = await rerank({
  model: cohere.reranking('rerank-english-v3.0'),
  query: 'ç”¨æˆ·æŸ¥è¯¢',
  documents: documents.map(d => d.text),
  topN: 3,  // è¿”å›å‰3ä¸ª
});

// æŒ‰ç›¸å…³æ€§æ’åºçš„ç»“æœ
rankings.forEach((ranking) => {
  console.log(documents[ranking.index], ranking.score);
});
```

---

## å¤šæ¨¡æ€åŠŸèƒ½

### generateImage - å›¾åƒç”Ÿæˆ

```typescript
import { generateImage } from 'ai';
import { openai } from '@ai-sdk/openai';

const { image } = await generateImage({
  model: openai.image('dall-e-3'),
  prompt: 'ä¸€åªæˆ´ç€å¢¨é•œçš„çŒ«',
  size: '1024x1024',
  n: 1,
  aspectRatio: '16:9',  // æˆ–æŒ‡å®š size
  seed: 12345,  // å¯é€‰ï¼šå›ºå®šç§å­
});

console.log(image.url);  // å›¾ç‰‡ URL
console.log(image.base64);  // Base64 æ•°æ®
```

### generateSpeech - è¯­éŸ³åˆæˆ

```typescript
import { generateSpeech } from 'ai';
import { openai } from '@ai-sdk/openai';

const { audio } = await generateSpeech({
  model: openai.speech('tts-1'),
  text: 'ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ AI SDK',
  voice: 'alloy',  // alloy, echo, fable, onyx, nova, shimmer
  speed: 1.0,
  outputFormat: 'mp3',
});

// æ’­æ”¾éŸ³é¢‘
const audioBlob = new Blob([audio], { type: 'audio/mp3' });
const audioUrl = URL.createObjectURL(audioBlob);
const audioElement = new Audio(audioUrl);
audioElement.play();
```

### transcribe - è¯­éŸ³è½¬æ–‡å­—

```typescript
import { transcribe } from 'ai';
import { openai } from '@ai-sdk/openai';

const { text } = await transcribe({
  model: openai.transcription('whisper-1'),
  audio: audioFile,  // File å¯¹è±¡æˆ– Uint8Array
});

console.log('è½¬å½•ç»“æœ:', text);
```

---

## å®æˆ˜ç»„åˆç¤ºä¾‹

### 1. å¸¦æ¨ç†è¿‡ç¨‹çš„ç»“æ„åŒ–è¾“å‡º

```typescript
import { generateText, output, wrapLanguageModel, extractReasoningMiddleware } from 'ai';
import { z } from 'zod';

const modelWithReasoning = wrapLanguageModel({
  model: chatModel,
  middleware: extractReasoningMiddleware({ tagName: 'thinking' }),
});

const result = await generateText({
  model: modelWithReasoning,
  prompt: 'åˆ†æè¿™ä¸ªäº§å“è¯„è®ºï¼š"å¤ªæ£’äº†ï¼Œæ€§ä»·æ¯”é«˜ï¼"',
  output: output.object({
    schema: z.object({
      sentiment: z.enum(['positive', 'negative', 'neutral']),
      confidence: z.number().min(0).max(1),
      keywords: z.array(z.string()),
    }),
  }),
});

console.log('æ¨ç†è¿‡ç¨‹:', result.reasoning);
console.log('åˆ†æç»“æœ:', result.object);
// { sentiment: 'positive', confidence: 0.95, keywords: ['æ£’', 'æ€§ä»·æ¯”'] }
```

### 2. å¸¦æ–‡ä»¶ä¸Šä¼ çš„æ™ºèƒ½å¯¹è¯

```typescript
const ChatWithFiles = () => {
  const { messages, sendMessage } = useChat();

  const handleSubmit = async (text: string, files: FileList) => {
    const fileParts = await convertFileListToFileUIParts(files);

    await sendMessage({
      text,
      parts: [
        { type: 'text', text },
        ...fileParts,
      ],
    });
  };

  return (
    <div>
      {messages.map((msg) => (
        <div key={msg.id}>
          {msg.parts.map((part, i) => {
            if (isTextUIPart(part)) return <p key={i}>{part.text}</p>;
            if (isFileUIPart(part)) return <img key={i} src={part.url} />;
            if (isReasoningUIPart(part)) {
              return <details key={i}><summary>æ€è€ƒè¿‡ç¨‹</summary>{part.text}</details>;
            }
          })}
        </div>
      ))}
    </div>
  );
};
```

### 3. å¸¦ä¿®å‰ªçš„é•¿å¯¹è¯ä¼˜åŒ–

```typescript
const OptimizedChat = () => {
  const { messages, sendMessage } = useChat();

  const handleSend = async (text: string) => {
    // ä¿®å‰ªå†å²æ¶ˆæ¯
    const prunedMessages = pruneMessages({
      messages: convertToModelMessages(messages),
      reasoning: 'none',  // ç§»é™¤æ¨ç†èŠ‚çœ token
      toolCalls: 'before-last-5-messages',
      emptyMessages: 'remove',
    });

    await sendMessage(text, {
      body: { messages: prunedMessages }
    });
  };

  return <ChatInterface onSend={handleSend} />;
};
```

---

## æ€»ç»“ï¼šå¸¸ç”¨åŠŸèƒ½é€ŸæŸ¥è¡¨

| åŠŸèƒ½ | ç”¨é€” | å…¸å‹åœºæ™¯ |
|------|------|---------|
| `pruneMessages` | ä¿®å‰ªå†å²æ¶ˆæ¯ | é•¿å¯¹è¯ä¼˜åŒ–ã€èŠ‚çœ token |
| `smoothStream` | å¹³æ»‘æµå¼è¾“å‡º | æå‡ç”¨æˆ·ä½“éªŒã€ä¸­æ–‡é€å­—è¾“å‡º |
| `output.object()` | ç»“æ„åŒ–è¾“å‡º | æ›¿ä»£ generateObjectï¼Œç±»å‹å®‰å…¨ |
| `extractReasoningMiddleware` | æå–æ¨ç†è¿‡ç¨‹ | æ˜¾ç¤º AI"æ€è€ƒ"ã€è°ƒè¯• |
| `isToolUIPart` | ç±»å‹å®ˆå« | å®‰å…¨å¤„ç†æ¶ˆæ¯éƒ¨åˆ† |
| `convertFileListToFileUIParts` | æ–‡ä»¶ä¸Šä¼  | å¤šæ¨¡æ€å¯¹è¯ |
| `embed` / `embedMany` | åµŒå…¥å‘é‡ | RAGã€è¯­ä¹‰æœç´¢ |
| `rerank` | é‡æ’åº | ä¼˜åŒ–æœç´¢ç»“æœ |
| `stepCountIs` | é™åˆ¶æ­¥éª¤ | é˜²æ­¢ Agent æ— é™å¾ªç¯ |
| `addToolInputExamplesMiddleware` | å·¥å…·ç¤ºä¾‹ | æå‡å·¥å…·è°ƒç”¨å‡†ç¡®æ€§ |

---

## å‚è€ƒèµ„æ–™

- ç±»å‹å®šä¹‰: `node_modules/ai/dist/index.d.ts`
- AI SDK å®˜æ–¹æ–‡æ¡£: https://sdk.vercel.ai/docs
- ç›¸å…³æ–‡æ¡£: `ai-sdk-v6-guide.md`
